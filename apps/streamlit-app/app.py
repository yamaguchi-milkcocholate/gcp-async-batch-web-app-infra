"""Streamlit ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³.

PDFä¸€æ‹¬è§£æã‚·ã‚¹ãƒ†ãƒ ã®ãƒ¡ã‚¤ãƒ³UIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’å—ã‘ä»˜ã‘ã€éåŒæœŸãƒãƒƒãƒå‡¦ç†ã‚’ãƒˆãƒªã‚¬ãƒ¼ã—ã€
å‡¦ç†çŠ¶æ³ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«è¡¨ç¤ºã—ã€å®Œäº†å¾Œã«çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’æä¾›ã™ã‚‹ã€‚
"""

import json
import time
import uuid
from datetime import UTC, datetime

import redis
import streamlit as st
from loguru import logger

from config import Settings
from pubsub_client import PubSubClient
from storage import get_storage_client

# è¨­å®šèª­ã¿è¾¼ã¿
settings = Settings()
storage_client = get_storage_client(settings)

# Redisã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
redis_client = redis.Redis(
    host=settings.redis_host,
    port=settings.redis_port,
    db=settings.redis_db,
    decode_responses=True,
)

# Pub/Subã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
if not settings.gcp_project_id:
    st.error("GCP_PROJECT_ID ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

pubsub_client = PubSubClient(settings.gcp_project_id, settings.pubsub_topic)

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="PDFä¸€æ‹¬è§£æã‚·ã‚¹ãƒ†ãƒ ",
    page_icon="ğŸ“„",
    layout="centered",
)

st.title("ğŸ“„ PDFä¸€æ‹¬è§£æã‚·ã‚¹ãƒ†ãƒ ")
st.markdown("PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€AI ã«ã‚ˆã‚‹ä¸€æ‹¬è§£æã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚")

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼
uploaded_file = st.file_uploader(
    "PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
    type=["pdf"],
    help="æœ€å¤§100MBã¾ã§ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚",
)

if uploaded_file is not None:
    # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±è¡¨ç¤º
    st.info(
        f"ğŸ“ é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_file.name} ({uploaded_file.size / 1024 / 1024:.2f} MB)"
    )

    if st.button("ğŸš€ è§£æé–‹å§‹", type="primary"):
        try:
            # ã‚¸ãƒ§ãƒ–IDç”Ÿæˆ
            job_id = str(uuid.uuid4())
            logger.info(f"Starting job {job_id} for file {uploaded_file.name}")

            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            destination_path = f"uploads/{job_id}/{uploaded_file.name}"
            file_bytes = uploaded_file.read()
            storage_client.upload_file(file_bytes, destination_path)
            logger.info(f"File uploaded: {destination_path}")

            # Pub/Subãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç™ºè¡Œ
            message = {
                "job_id": job_id,
                "pdf_path": destination_path,
                "bucket_name": settings.gcs_bucket_name or "local",
                "timestamp": datetime.now(UTC).isoformat(),
            }
            message_id = pubsub_client.publish_message(message)
            logger.info(f"Published Pub/Sub message: {message_id}")

            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
            st.session_state["job_id"] = job_id
            st.success(f"âœ… å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã—ãŸï¼ˆJob ID: `{job_id}`ï¼‰")

        except Exception as e:
            logger.error(f"Error starting job: {e}")
            st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç›£è¦–
if "job_id" in st.session_state:
    job_id = st.session_state["job_id"]

    st.divider()
    st.subheader("ğŸ“Š å‡¦ç†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹")

    try:
        # Redisã‹ã‚‰ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—
        job_key = f"job:{job_id}"
        job_data_str = redis_client.get(job_key)

        if job_data_str:
            job_data = json.loads(job_data_str)
            status = job_data.get("status", "unknown")
            progress = job_data.get("progress", 0)
            message = job_data.get("message", "")
            error_msg = job_data.get("error_msg", "")
            result_url = job_data.get("result_url", "")

            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
            if status == "pending":
                st.info("â³ å‡¦ç†å¾…æ©Ÿä¸­...")
            elif status == "processing":
                st.info(f"âš™ï¸ å‡¦ç†ä¸­: {message}")
                st.progress(progress / 100, text=f"{progress}% å®Œäº†")
            elif status == "completed":
                st.success("âœ… å‡¦ç†å®Œäº†ï¼")
                if result_url:
                    # çµæœãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                    try:
                        result_bytes = storage_client.download_file(result_url)
                        st.download_button(
                            label="ğŸ“¥ çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=result_bytes,
                            file_name=f"result_{job_id}.md",
                            mime="text/markdown",
                        )
                    except Exception as e:
                        logger.error(f"Error downloading result: {e}")
                        st.error(f"çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            elif status == "error":
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error_msg}")
            else:
                st.warning(f"âš ï¸ ä¸æ˜ãªã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {status}")

            # å‡¦ç†ä¸­ã®å ´åˆã¯2ç§’å¾Œã«å†èª­ã¿è¾¼ã¿
            if status in ["pending", "processing"]:
                time.sleep(2)
                st.rerun()
        else:
            st.warning("âš ï¸ ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å‡¦ç†ãŒé–‹å§‹ã•ã‚Œã‚‹ã¾ã§ãŠå¾…ã¡ãã ã•ã„...")
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã‚‚å†èª­ã¿è¾¼ã¿ï¼ˆå‡¦ç†é–‹å§‹å‰ã®å¯èƒ½æ€§ï¼‰
            time.sleep(2)
            st.rerun()

    except redis.RedisError as e:
        logger.error(f"Redis connection error: {e}")
        st.error("âŒ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: Redisæ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ")
    except Exception as e:
        logger.error(f"Error fetching job status: {e}")
        st.error(f"âŒ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
