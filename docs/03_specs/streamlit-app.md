# Spec: Streamlit Frontend Application

## 1. æ¦‚è¦

PDFä¸€æ‹¬è§£æãƒãƒƒãƒå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’å—ã‘ä»˜ã‘ã€éåŒæœŸãƒãƒƒãƒå‡¦ç†ã‚’ãƒˆãƒªã‚¬ãƒ¼ã—ã€å‡¦ç†çŠ¶æ³ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«è¡¨ç¤ºã—ã€å®Œäº†å¾Œã«çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’æä¾›ã™ã‚‹ã€‚

## 2. å¤‰æ›´ã®ç›®çš„

- **ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹**: 3ã‚¿ãƒ–æ§‹æˆ(ã‚¸ãƒ§ãƒ–ç™»éŒ²/ã‚¸ãƒ§ãƒ–ä¸€è¦§/ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª)ã«ã‚ˆã‚‹ç›´æ„Ÿçš„ãªUI
- **éåŒæœŸå‡¦ç†ã®èµ·ç‚¹**: Pub/Subã¸ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç™ºè¡Œã«ã‚ˆã‚‹å‡¦ç†é–‹å§‹
- **ã‚¸ãƒ§ãƒ–å±¥æ­´ç®¡ç†**: éå»24æ™‚é–“ã®ã‚¸ãƒ§ãƒ–ä¸€è¦§è¡¨ç¤ºã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª
- **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯**: Redisãƒãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹å‡¦ç†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã¨é€²æ—ç‡ã®å¯è¦–åŒ–
- **çµæœé…ä¿¡**: å‡¦ç†å®Œäº†å¾Œã®çµ±åˆãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æä¾›
- **ãƒªãƒ­ãƒ¼ãƒ‰è€æ€§**: ãƒ–ãƒ©ã‚¦ã‚¶ãƒªãƒ­ãƒ¼ãƒ‰å¾Œã‚‚ã‚¸ãƒ§ãƒ–ä¸€è¦§ã‹ã‚‰å‡¦ç†ä¸­ã®ã‚¸ãƒ§ãƒ–ã‚’è¿½è·¡å¯èƒ½

## 3. æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

- **Framework**: Streamlit (æœ€æ–°å®‰å®šç‰ˆ)
- **è¨€èª**: Python 3.12+
- **ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç®¡ç†**: `uv`
- **ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒª**:
  - `streamlit`: UIãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
  - `redis`: Redisã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—ï¼‰
  - `google-cloud-pubsub`: Pub/Subã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç™ºè¡Œï¼‰
  - `google-cloud-storage`: GCSã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼‰
  - `pydantic-settings`: ç’°å¢ƒå¤‰æ•°ç®¡ç†
  - `loguru`: æ§‹é€ åŒ–ãƒ­ã‚°å‡ºåŠ›

## 4. æ©Ÿèƒ½è¦ä»¶

### 4.1. UIæ§‹æˆï¼ˆ3ã‚¿ãƒ–ï¼‰

#### ã‚¿ãƒ–1: ğŸ“¤ ã‚¸ãƒ§ãƒ–ç™»éŒ²

PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨ã‚¸ãƒ§ãƒ–ç™»éŒ²ã‚’è¡Œã†ã€‚

- Streamlitã® `st.file_uploader` ã‚’ä½¿ç”¨
- **å¯¾å¿œå½¢å¼**: PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ï¼ˆ`.pdf`ï¼‰
- **ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ¶é™**: æœ€å¤§100MBï¼ˆStreamlit ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§èª¿æ•´å¯èƒ½ï¼‰
- **ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å…ˆ**:
  - ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒï¼ˆ`STORAGE_TYPE=LOCAL`ï¼‰: `./local_storage/uploads/{job_id}/{filename}`
  - æœ¬ç•ªç’°å¢ƒï¼ˆ`STORAGE_TYPE=GCP`ï¼‰: `gs://{bucket_name}/uploads/{job_id}/{filename}`

**å‡¦ç†ãƒ•ãƒ­ãƒ¼:**
1. ã‚¸ãƒ§ãƒ–IDç”Ÿæˆ: `uuid.uuid4()` ã‚’ä½¿ç”¨ï¼ˆä¾‹: `f47ac10b-58cc-4372-a567-0e02b2c3d479`ï¼‰
2. ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
3. Pub/Subãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç™ºè¡Œï¼ˆå‡¦ç†é–‹å§‹ãƒˆãƒªã‚¬ãƒ¼ï¼‰
4. æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤ºï¼ˆJob IDã‚’å«ã‚€ï¼‰

**Pub/Subãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼:**

```json
{
  "job_id": "f47ac10b-58cc-4372-a567-0e02b2c3d479",
  "pdf_path": "uploads/f47ac10b-58cc-4372-a567-0e02b2c3d479/document.pdf",
  "bucket_name": "my-bucket",
  "timestamp": "2026-02-12T06:30:00Z"
}
```

- **ãƒˆãƒ”ãƒƒã‚¯å**: ç’°å¢ƒå¤‰æ•° `PUBSUB_TOPIC` ã§æŒ‡å®šï¼ˆä¾‹: `pdf-processing-topic`ï¼‰

#### ã‚¿ãƒ–2: ğŸ“‹ ã‚¸ãƒ§ãƒ–ä¸€è¦§

éå»24æ™‚é–“ã«ç™»éŒ²ã•ã‚ŒãŸå…¨ã‚¸ãƒ§ãƒ–ã‚’ä¸€è¦§è¡¨ç¤ºã™ã‚‹ã€‚

**å–å¾—æ–¹æ³•:**
- Redis SCAN ã‚³ãƒãƒ³ãƒ‰ã§ `job:*` ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã‚­ãƒ¼ã‚’å…¨ã¦å–å¾—
- å„ã‚­ãƒ¼ã‹ã‚‰ `updated_at` ã‚’å–å¾—ã—ã€é™é †ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰

**ä¸€è¦§è¡¨ç¤ºé …ç›®:**

| é …ç›® | å†…å®¹ | ä¾‹ |
|------|------|-----|
| Job ID | ã‚¸ãƒ§ãƒ–è­˜åˆ¥å­ï¼ˆå…ˆé ­8æ–‡å­—ï¼‰ | `f47ac10b` |
| ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ | `pending`, `processing`, `completed`, `failed` | ğŸŸ¡ å‡¦ç†ä¸­ |
| é€²æ— | é€²æ—ç‡ï¼ˆ%ï¼‰ | 45% |
| æ›´æ–°æ—¥æ™‚ | æœ€çµ‚æ›´æ–°æ™‚åˆ» | 2026-02-12 06:35:00 |
| ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ | ã€Œè©³ç´°ã‚’è¦‹ã‚‹ã€ãƒœã‚¿ãƒ³ | ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§é¸æŠ |

**å®Ÿè£…è©³ç´°:**
```python
# Redis SCAN ã§ã‚¸ãƒ§ãƒ–ä¸€è¦§å–å¾—
cursor = 0
jobs = []
while True:
    cursor, keys = redis_client.scan(cursor, match="job:*", count=100)
    for key in keys:
        job_data_str = redis_client.get(key)
        if job_data_str:
            job_data = json.loads(job_data_str)
            job_data["job_id"] = key.replace("job:", "")
            jobs.append(job_data)
    if cursor == 0:
        break

# updated_at ã§ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
jobs.sort(key=lambda x: x.get("updated_at", ""), reverse=True)
```

**UIè¦ä»¶:**
- ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã«å¿œã˜ãŸã‚¢ã‚¤ã‚³ãƒ³è¡¨ç¤º:
  - `pending`: ğŸŸ¡ å¾…æ©Ÿä¸­
  - `processing`: ğŸ”µ å‡¦ç†ä¸­
  - `completed`: ğŸŸ¢ å®Œäº†
  - `failed`: ğŸ”´ å¤±æ•—
- ã€Œè©³ç´°ã‚’è¦‹ã‚‹ã€ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§ `st.session_state["selected_job_id"]` ã«ä¿å­˜

#### ã‚¿ãƒ–3: ğŸ“Š ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª

é¸æŠã—ãŸã‚¸ãƒ§ãƒ–ã®è©³ç´°ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’è¡¨ç¤ºã—ã€å®Œäº†æ™‚ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’æä¾›ã™ã‚‹ã€‚

**å‰ææ¡ä»¶:**
- ã‚¿ãƒ–2ã§ã€Œè©³ç´°ã‚’è¦‹ã‚‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ãŸã‚¸ãƒ§ãƒ–ã€ã¾ãŸã¯ç›´è¿‘ã§ç™»éŒ²ã—ãŸã‚¸ãƒ§ãƒ–

**è¡¨ç¤ºå†…å®¹:**
- **ã‚¸ãƒ§ãƒ–ID**: `st.code()` ã§ãƒ•ãƒ«IDã‚’è¡¨ç¤º
- **ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: ç¾åœ¨ã®å‡¦ç†çŠ¶æ…‹
- **é€²æ—ãƒãƒ¼**: `st.progress()` ã§é€²æ—ç‡ã‚’å¯è¦–åŒ–
- **ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸**: ç¾åœ¨ã®å‡¦ç†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆä¾‹: "Page 5/12 analyzing..."ï¼‰
- **æ›´æ–°æ—¥æ™‚**: æœ€çµ‚æ›´æ–°æ™‚åˆ»
- **ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸**: å¤±æ•—æ™‚ã®ã¿è¡¨ç¤º

**Redisãƒ‡ãƒ¼ã‚¿å½¢å¼:**

```json
{
  "status": "processing",
  "progress": 45,
  "message": "Page 5/12 analyzing...",
  "result_url": "",
  "error_msg": "",
  "updated_at": "2026-02-12T06:35:00Z"
}
```

- **ã‚­ãƒ¼å½¢å¼**: `job:{job_id}`
- **TTL**: 24æ™‚é–“ï¼ˆ86400ç§’ï¼‰- ãƒ¯ãƒ¼ã‚«ãƒ¼å´ã§è¨­å®š

**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥UIè¡¨ç¤º:**

| status | è¡¨ç¤º | å‹•ä½œ |
|--------|------|------|
| `pending` | ğŸŸ¡ å‡¦ç†å¾…æ©Ÿä¸­... | 2ç§’å¾Œã«è‡ªå‹•ãƒªãƒ­ãƒ¼ãƒ‰ |
| `processing` | ğŸ”µ å‡¦ç†ä¸­: {message}<br>ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ | 2ç§’å¾Œã«è‡ªå‹•ãƒªãƒ­ãƒ¼ãƒ‰ |
| `completed` | ğŸŸ¢ å‡¦ç†å®Œäº†ï¼<br>ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ | ãƒªãƒ­ãƒ¼ãƒ‰ãªã— |
| `failed` | ğŸ”´ ã‚¨ãƒ©ãƒ¼: {error_msg} | ãƒªãƒ­ãƒ¼ãƒ‰ãªã— |

**è‡ªå‹•æ›´æ–°:**
- `status` ãŒ `pending` ã¾ãŸã¯ `processing` ã®å ´åˆã€2ç§’å¾Œã« `st.rerun()` ã§è‡ªå‹•æ›´æ–°

### 4.2. çµæœãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

- **æ¡ä»¶**: `status == "completed"` ã‹ã¤ `result_url` ãŒå­˜åœ¨ã™ã‚‹å ´åˆ
- **å®Ÿè£…**:
  - ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ: `result_url` ã®ãƒ‘ã‚¹ã‹ã‚‰ç›´æ¥ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
  - æœ¬ç•ªç’°å¢ƒ: GCSã‹ã‚‰ `result_url` ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
- **UI**: `st.download_button()` ã§çµæœãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ`.json` ã¾ãŸã¯ `.md`ï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æä¾›

### 4.3. ãƒ‡ãƒ¼ã‚¿æ°¸ç¶šæ€§ã¨ãƒªãƒ­ãƒ¼ãƒ‰è€æ€§

**å•é¡Œç‚¹ï¼ˆæ—§å®Ÿè£…ï¼‰:**
- `st.session_state` ã®ã¿ã«ã‚¸ãƒ§ãƒ–IDã‚’ä¿å­˜
- ãƒ–ãƒ©ã‚¦ã‚¶ãƒªãƒ­ãƒ¼ãƒ‰æ™‚ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆãŒã‚¯ãƒªã‚¢ã•ã‚Œã€å‡¦ç†ä¸­ã®ã‚¸ãƒ§ãƒ–ã‚’è¿½è·¡ä¸å¯

**è§£æ±ºç­–ï¼ˆæ–°å®Ÿè£…ï¼‰:**
- Redis SCAN ã§éå»24æ™‚é–“ã®å…¨ã‚¸ãƒ§ãƒ–ã‚’å–å¾—å¯èƒ½
- ã‚¸ãƒ§ãƒ–ä¸€è¦§ã‹ã‚‰ä»»æ„ã®ã‚¸ãƒ§ãƒ–ã‚’é¸æŠã—ã¦è¿½è·¡å¯èƒ½
- ãƒªãƒ­ãƒ¼ãƒ‰å¾Œã‚‚ã‚¸ãƒ§ãƒ–ä¸€è¦§ã‹ã‚‰å‡¦ç†ä¸­ã®ã‚¸ãƒ§ãƒ–ã‚’å†é¸æŠã§ãã‚‹

## 5. Dockeræ§‹æˆ

### 5.1. ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 

```
apps/
â””â”€â”€ streamlit-app/
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ pyproject.toml
    â”œâ”€â”€ app.py
    â”œâ”€â”€ config.py
    â”œâ”€â”€ storage.py
    â””â”€â”€ pubsub_client.py
```

### 5.2. Dockerfileä»•æ§˜

- **ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ¡ãƒ¼ã‚¸**: `python:3.12-slim`
- **ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª**: `/app`
- **ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**: `uv` ã‚’ä½¿ç”¨
- **ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ**: `streamlit run app.py --server.port=8501 --server.address=0.0.0.0`
- **Hot Reloadå¯¾å¿œ**: ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºæ™‚ã¯ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’ãƒœãƒªãƒ¥ãƒ¼ãƒ ãƒã‚¦ãƒ³ãƒˆ

### 5.3. ç’°å¢ƒå¤‰æ•°

| å¤‰æ•°å                 | èª¬æ˜                                 | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤           | ä¾‹                                          |
| ---------------------- | ------------------------------------ | ---------------------- | ------------------------------------------- |
| `STORAGE_TYPE`         | ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¿ã‚¤ãƒ—ï¼ˆ`LOCAL` or `GCP`ï¼‰ | `LOCAL`                | `GCP`                                       |
| `LOCAL_STORAGE_PATH`   | ãƒ­ãƒ¼ã‚«ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®ãƒ‘ã‚¹             | `./local_storage`      | `/data`                                     |
| `GCS_BUCKET_NAME`      | GCSãƒã‚±ãƒƒãƒˆå                        | -                      | `pdf-processing-bucket`                     |
| `REDIS_HOST`           | Redisãƒ›ã‚¹ãƒˆ                          | `localhost`            | `redis`                                     |
| `REDIS_PORT`           | Redisãƒãƒ¼ãƒˆ                          | `6379`                 | `6379`                                      |
| `REDIS_DB`             | Redis DBç•ªå·                         | `0`                    | `0`                                         |
| `PUBSUB_EMULATOR_HOST` | Pub/Subã‚¨ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ›ã‚¹ãƒˆ            | -                      | `localhost:8085`                            |
| `PUBSUB_TOPIC`         | Pub/Subãƒˆãƒ”ãƒƒã‚¯å                    | `pdf-processing-topic` | `projects/my-project/topics/pdf-processing` |
| `GCP_PROJECT_ID`       | GCPãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID                    | -                      | `my-gcp-project`                            |

### 5.4. Docker Composeè¨­å®š

```yaml
services:
  app:
    build:
      context: ./apps/streamlit-app
      dockerfile: Dockerfile
    ports:
      - "8501:8501"
    volumes:
      - ./apps/streamlit-app:/app
      - ./local_storage:/app/local_storage
    environment:
      - STORAGE_TYPE=LOCAL
      - LOCAL_STORAGE_PATH=./local_storage
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - PUBSUB_EMULATOR_HOST=pubsub:8085
      - PUBSUB_TOPIC=pdf-processing-topic
      - GCP_PROJECT_ID=local-dev
    depends_on:
      - redis
      - pubsub
```

## 6. ã‚³ãƒ¼ãƒ‰è¨­è¨ˆ

### 6.1. ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹æˆ

#### `config.py` - è¨­å®šç®¡ç†

```python
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    storage_type: str = "LOCAL"
    local_storage_path: str = "./local_storage"
    gcs_bucket_name: str | None = None
    redis_host: str = "localhost"
    redis_port: int = 6379
    redis_db: int = 0
    pubsub_emulator_host: str | None = None
    pubsub_topic: str = "pdf-processing-topic"
    gcp_project_id: str | None = None

    class Config:
        env_file = ".env"
```

#### `storage.py` - ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æŠ½è±¡åŒ–ãƒ¬ã‚¤ãƒ¤ãƒ¼

```python
from abc import ABC, abstractmethod
from pathlib import Path

class StorageClient(ABC):
    @abstractmethod
    def upload_file(self, file_bytes: bytes, destination_path: str) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ãƒ‘ã‚¹ã‚’è¿”ã™"""
        pass

    @abstractmethod
    def download_file(self, source_path: str) -> bytes:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™"""
        pass

class LocalStorageClient(StorageClient):
    def __init__(self, base_path: str):
        self.base_path = Path(base_path)

    def upload_file(self, file_bytes: bytes, destination_path: str) -> str:
        # shutil ã‚’ä½¿ç”¨ã—ã¦ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã«ä¿å­˜
        pass

    def download_file(self, source_path: str) -> bytes:
        # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰èª­ã¿è¾¼ã¿
        pass

class GCSStorageClient(StorageClient):
    def __init__(self, bucket_name: str):
        from google.cloud import storage
        self.client = storage.Client()
        self.bucket = self.client.bucket(bucket_name)

    def upload_file(self, file_bytes: bytes, destination_path: str) -> str:
        # GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        pass

    def download_file(self, source_path: str) -> bytes:
        # GCSã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        pass

def get_storage_client(settings: Settings) -> StorageClient:
    if settings.storage_type == "LOCAL":
        return LocalStorageClient(settings.local_storage_path)
    elif settings.storage_type == "GCP":
        return GCSStorageClient(settings.gcs_bucket_name)
    else:
        raise ValueError(f"Unknown storage type: {settings.storage_type}")
```

#### `pubsub_client.py` - Pub/Subã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ

```python
import json
from google.cloud import pubsub_v1
from loguru import logger

class PubSubClient:
    def __init__(self, project_id: str, topic_name: str):
        self.publisher = pubsub_v1.PublisherClient()
        self.topic_path = self.publisher.topic_path(project_id, topic_name)

    def publish_message(self, message: dict) -> str:
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç™ºè¡Œã—ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸IDã‚’è¿”ã™"""
        message_bytes = json.dumps(message).encode("utf-8")
        future = self.publisher.publish(self.topic_path, message_bytes)
        message_id = future.result()
        logger.info(f"Published message {message_id}: {message}")
        return message_id
```

#### `app.py` - ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆ3ã‚¿ãƒ–æ§‹æˆï¼‰

```python
import streamlit as st
import redis
import uuid
import time
import json
from datetime import datetime, UTC
from loguru import logger
from config import Settings
from storage import get_storage_client
from pubsub_client import PubSubClient

# è¨­å®šèª­ã¿è¾¼ã¿
settings = Settings()
storage_client = get_storage_client(settings)
redis_client = redis.Redis(
    host=settings.redis_host,
    port=settings.redis_port,
    db=settings.redis_db,
    decode_responses=True
)
pubsub_client = PubSubClient(settings.gcp_project_id, settings.pubsub_topic)

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="PDFä¸€æ‹¬è§£æã‚·ã‚¹ãƒ†ãƒ ",
    page_icon="ğŸ“„",
    layout="wide",
)

st.title("ğŸ“„ PDFä¸€æ‹¬è§£æã‚·ã‚¹ãƒ†ãƒ ")

# 3ã‚¿ãƒ–æ§‹æˆ
tab1, tab2, tab3 = st.tabs(["ğŸ“¤ ã‚¸ãƒ§ãƒ–ç™»éŒ²", "ğŸ“‹ ã‚¸ãƒ§ãƒ–ä¸€è¦§", "ğŸ“Š ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª"])

# ========================================
# ã‚¿ãƒ–1: ã‚¸ãƒ§ãƒ–ç™»éŒ²
# ========================================
with tab1:
    st.header("PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")

    uploaded_file = st.file_uploader(
        "PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        type=["pdf"],
        help="æœ€å¤§100MBã¾ã§ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚",
    )

    if uploaded_file is not None:
        st.info(
            f"ğŸ“ é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_file.name} "
            f"({uploaded_file.size / 1024 / 1024:.2f} MB)"
        )

        if st.button("ğŸš€ è§£æé–‹å§‹", type="primary"):
            try:
                # ã‚¸ãƒ§ãƒ–IDç”Ÿæˆ
                job_id = str(uuid.uuid4())
                logger.info(f"Starting job {job_id} for file {uploaded_file.name}")

                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                destination_path = f"uploads/{job_id}/{uploaded_file.name}"
                file_bytes = uploaded_file.read()
                storage_client.upload_file(file_bytes, destination_path)
                logger.info(f"File uploaded: {destination_path}")

                # Pub/Subãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç™ºè¡Œ
                message = {
                    "job_id": job_id,
                    "pdf_path": destination_path,
                    "bucket_name": settings.gcs_bucket_name or "local",
                    "timestamp": datetime.now(UTC).isoformat(),
                }
                message_id = pubsub_client.publish_message(message)
                logger.info(f"Published Pub/Sub message: {message_id}")

                # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜ï¼ˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèªã‚¿ãƒ–ã§ä½¿ç”¨ï¼‰
                st.session_state["selected_job_id"] = job_id

                st.success(
                    f"âœ… å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã—ãŸ\n\n"
                    f"**Job ID**: `{job_id}`\n\n"
                    f"ã€Œã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèªã€ã‚¿ãƒ–ã§é€²æ—ã‚’ç¢ºèªã§ãã¾ã™ã€‚"
                )

            except Exception as e:
                logger.error(f"Error starting job: {e}")
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# ========================================
# ã‚¿ãƒ–2: ã‚¸ãƒ§ãƒ–ä¸€è¦§
# ========================================
with tab2:
    st.header("éå»24æ™‚é–“ã®ã‚¸ãƒ§ãƒ–ä¸€è¦§")

    try:
        # Redis SCAN ã§job:*ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã‚­ãƒ¼ã‚’å…¨ã¦å–å¾—
        cursor = 0
        jobs = []
        while True:
            cursor, keys = redis_client.scan(cursor, match="job:*", count=100)
            for key in keys:
                job_data_str = redis_client.get(key)
                if job_data_str:
                    job_data = json.loads(job_data_str)
                    job_data["job_id"] = key.replace("job:", "")
                    jobs.append(job_data)
            if cursor == 0:
                break

        if not jobs:
            st.info("ã‚¸ãƒ§ãƒ–ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            # updated_at ã§ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
            jobs.sort(key=lambda x: x.get("updated_at", ""), reverse=True)

            # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
            for job in jobs:
                job_id = job.get("job_id", "unknown")
                status = job.get("status", "unknown")
                progress = job.get("progress", 0)
                updated_at = job.get("updated_at", "")

                # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¢ã‚¤ã‚³ãƒ³
                status_icons = {
                    "pending": "ğŸŸ¡",
                    "processing": "ğŸ”µ",
                    "completed": "ğŸŸ¢",
                    "failed": "ğŸ”´",
                }
                icon = status_icons.get(status, "âšª")

                # è¡Œè¡¨ç¤º
                col1, col2, col3, col4, col5 = st.columns([2, 2, 1, 2, 1])
                with col1:
                    st.text(f"{job_id[:8]}...")
                with col2:
                    st.text(f"{icon} {status}")
                with col3:
                    st.text(f"{progress}%")
                with col4:
                    st.text(updated_at[:19] if updated_at else "")
                with col5:
                    if st.button("è©³ç´°", key=f"select_{job_id}"):
                        st.session_state["selected_job_id"] = job_id
                        st.success(f"ã‚¸ãƒ§ãƒ– `{job_id[:8]}...` ã‚’é¸æŠã—ã¾ã—ãŸ")
                        st.rerun()

    except redis.RedisError as e:
        logger.error(f"Redis connection error: {e}")
        st.error("âŒ Redisæ¥ç¶šã‚¨ãƒ©ãƒ¼")
    except Exception as e:
        logger.error(f"Error fetching job list: {e}")
        st.error(f"âŒ ã‚¸ãƒ§ãƒ–ä¸€è¦§ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

# ========================================
# ã‚¿ãƒ–3: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª
# ========================================
with tab3:
    st.header("ã‚¸ãƒ§ãƒ–ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª")

    # é¸æŠã•ã‚ŒãŸã‚¸ãƒ§ãƒ–IDã‚’å–å¾—
    selected_job_id = st.session_state.get("selected_job_id")

    if not selected_job_id:
        st.warning("âš ï¸ ã‚¸ãƒ§ãƒ–ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã€Œã‚¸ãƒ§ãƒ–ä¸€è¦§ã€ã‚¿ãƒ–ã‹ã‚‰ã‚¸ãƒ§ãƒ–ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
    else:
        st.subheader(f"Job ID: `{selected_job_id}`")

        try:
            # Redisã‹ã‚‰ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—
            job_key = f"job:{selected_job_id}"
            job_data_str = redis_client.get(job_key)

            if not job_data_str:
                st.warning(
                    "âš ï¸ ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\n\n"
                    "- å‡¦ç†ãŒé–‹å§‹ã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™\n"
                    "- 24æ™‚é–“ä»¥ä¸ŠçµŒéã—ã¦ãƒ‡ãƒ¼ã‚¿ãŒå‰Šé™¤ã•ã‚ŒãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™"
                )
            else:
                job_data = json.loads(job_data_str)
                status = job_data.get("status", "unknown")
                progress = job_data.get("progress", 0)
                message = job_data.get("message", "")
                error_msg = job_data.get("error_msg", "")
                result_url = job_data.get("result_url", "")
                updated_at = job_data.get("updated_at", "")

                # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
                if status == "pending":
                    st.info("ğŸŸ¡ å‡¦ç†å¾…æ©Ÿä¸­...")
                    st.text(f"æ›´æ–°æ—¥æ™‚: {updated_at}")
                    time.sleep(2)
                    st.rerun()

                elif status == "processing":
                    st.info(f"ğŸ”µ å‡¦ç†ä¸­: {message}")
                    st.progress(progress / 100, text=f"{progress}% å®Œäº†")
                    st.text(f"æ›´æ–°æ—¥æ™‚: {updated_at}")
                    time.sleep(2)
                    st.rerun()

                elif status == "completed":
                    st.success("ğŸŸ¢ å‡¦ç†å®Œäº†ï¼")
                    st.text(f"æ›´æ–°æ—¥æ™‚: {updated_at}")

                    if result_url:
                        try:
                            result_bytes = storage_client.download_file(result_url)
                            st.download_button(
                                label="ğŸ“¥ çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                data=result_bytes,
                                file_name=f"result_{selected_job_id}.json",
                                mime="application/json",
                            )
                        except Exception as e:
                            logger.error(f"Error downloading result: {e}")
                            st.error(f"çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                    else:
                        st.warning("çµæœURLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

                elif status == "failed":
                    st.error(f"ğŸ”´ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
                    st.error(f"**ã‚¨ãƒ©ãƒ¼å†…å®¹**: {error_msg}")
                    st.text(f"æ›´æ–°æ—¥æ™‚: {updated_at}")

                else:
                    st.warning(f"âš ï¸ ä¸æ˜ãªã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {status}")

        except redis.RedisError as e:
            logger.error(f"Redis connection error: {e}")
            st.error("âŒ Redisæ¥ç¶šã‚¨ãƒ©ãƒ¼")
        except Exception as e:
            logger.error(f"Error fetching job status: {e}")
            st.error(f"âŒ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
```

## 7. ãƒ†ã‚¹ãƒˆæ–¹æ³•

### 7.1. ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç’°å¢ƒã§ã®å‹•ä½œç¢ºèª

1. Docker Composeã§å…¨ã‚µãƒ¼ãƒ“ã‚¹èµ·å‹•:

   ```bash
   docker-compose up
   ```

2. ãƒ–ãƒ©ã‚¦ã‚¶ã§ `http://localhost:8501` ã«ã‚¢ã‚¯ã‚»ã‚¹

3. PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ã€Œè§£æé–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯

4. é€²æ—è¡¨ç¤ºãŒæ›´æ–°ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆRedisã«ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’æ‰‹å‹•æŠ•å…¥ã—ã¦ç¢ºèªï¼‰

5. å‡¦ç†å®Œäº†å¾Œã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª

### 7.2. Redisãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿æŠ•å…¥

```bash
docker exec -it redis redis-cli
SET job:test-job-id '{"status":"processing","progress":50,"message":"Page 5/10 analyzing...","result_url":"","error_msg":"","updated_at":"2026-02-12T06:40:00Z"}'
```

## 8. éæ©Ÿèƒ½è¦ä»¶

- **ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³**: Streamlitã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã§å¯¾å¿œ
- **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**:
  - ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—æ™‚ã®ãƒªãƒˆãƒ©ã‚¤ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼è¡¨ç¤º
  - Redisæ¥ç¶šã‚¨ãƒ©ãƒ¼æ™‚ã®é©åˆ‡ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤º
  - Pub/Subç™ºè¡Œå¤±æ•—æ™‚ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- **ãƒ­ã‚°å‡ºåŠ›**: `loguru` ã§æ§‹é€ åŒ–ãƒ­ã‚°ã‚’å‡ºåŠ›ï¼ˆINFO, ERROR ãƒ¬ãƒ™ãƒ«ï¼‰
- **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£**: æœ¬ç•ªç’°å¢ƒã§ã¯IAPã«ã‚ˆã‚‹èªè¨¼ã‚’ä»˜ä¸ï¼ˆã‚¤ãƒ³ãƒ•ãƒ©å´ã§è¨­å®šï¼‰

## 9. å®Ÿè£…æ¸ˆã¿æ©Ÿèƒ½

- âœ… **3ã‚¿ãƒ–UIæ§‹æˆ**: ã‚¸ãƒ§ãƒ–ç™»éŒ²/ä¸€è¦§/ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèªã®åˆ†é›¢
- âœ… **ã‚¸ãƒ§ãƒ–å±¥æ­´è¡¨ç¤º**: éå»24æ™‚é–“ã®ã‚¸ãƒ§ãƒ–ä¸€è¦§ï¼ˆRedis SCANï¼‰
- âœ… **ãƒªãƒ­ãƒ¼ãƒ‰è€æ€§**: ãƒ–ãƒ©ã‚¦ã‚¶ãƒªãƒ­ãƒ¼ãƒ‰å¾Œã‚‚ã‚¸ãƒ§ãƒ–è¿½è·¡å¯èƒ½
- âœ… **24æ™‚é–“TTL**: å¤ã„ã‚¸ãƒ§ãƒ–ãƒ‡ãƒ¼ã‚¿ã®è‡ªå‹•å‰Šé™¤

## 10. ä»Šå¾Œã®æ‹¡å¼µ

- **è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œ**: ä¸€åº¦ã«è¤‡æ•°PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
- **ã‚¸ãƒ§ãƒ–æ¤œç´¢ãƒ»ãƒ•ã‚£ãƒ«ã‚¿**: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥ãƒ•ã‚£ãƒ«ã‚¿ã€ã‚¸ãƒ§ãƒ–IDæ¤œç´¢
- **ã‚­ãƒ£ãƒ³ã‚»ãƒ«æ©Ÿèƒ½**: å‡¦ç†ä¸­ã‚¸ãƒ§ãƒ–ã®ã‚­ãƒ£ãƒ³ã‚»ãƒ«
- **é€šçŸ¥æ©Ÿèƒ½**: å‡¦ç†å®Œäº†æ™‚ã®ãƒ¡ãƒ¼ãƒ«é€šçŸ¥
- **ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³**: ã‚¸ãƒ§ãƒ–ä¸€è¦§ã®å¤§é‡ãƒ‡ãƒ¼ã‚¿å¯¾å¿œ
